

\section{Fit Indexes Considered in the Study}
The fit indices considered in this study are grouped into three categories of model selection: likelihood ratio based test, information criteria and entropy based measures. Specifically we evaluate LMS-LRT, BLRT, AIC, CAIC, BIC, ABIC, relative entropy and ICL. A detailed description of each fit index is discussed. 

\subsection{Likelihood ratio based test}
Likelihood ratio based test are one of the most common ways to compare the relative fit of two nested models based on the difference of their log likelihoods. The LRT is defined as 







In our simulation, we consider the LMS-LRT and BLRT. 





\subsection{Information Criteria}
\hspace{1em} Next we examine the performance of AIC, BIC, SBIC and CAIC. Theoretically almost all information criteria are derived from the same foundation framework. A unique penalty term is included on the log likelihood measuring the complexity of the model by taking account the number of parameters and sample size. Because of the different penalty terms that can be imposed, Lin & Dayton (1997) says an infinite number of ICs can be produced. Sclove's (1987) equation summarizes the general relationship shared among ICs which takes the form of 

\begin{align}
    -2 \hspace{0.2em} log \hspace{0.2em} [max \hspace{0.2em} L(j)] + a(n)m(j) + b(j,n)
\end{align}
where $n$ is the sample size, max $L(j)$ denotes the maximum likelihood over the parameters, and $m(j)$ is the number of independent parameters in the $j$-th model. For any criterion, $a(n)$ is the cost of fitting an additional parameter and $b(j,n)$ is an additional term depending on the criterion and the model $j$ (Sclove, 1987). For example AIC is formulated with $a(n)=2$ for all sample sizes and $b(k,n)=0$. Similarly BIC is formulated with $a(n)=log(n)$ and $b(k,n)=0$. Table 4.1 shows all the information criterion considered in this study based on Sclove's equation

\begin{table}
    \caption{Summary of information criterion considered in study.}
    \label{tab:my_label}
    \vspace{1em}
    \centering
    \begin{adjustbox}{max width=\textwidth}
    \begin{tabular}{c c c}
    \toprule
    Information Criterion & $a(n)$ & $b(j,n)$ \\
    \midrule
  AIC & $2$ & $0$ \\
  BIC & $log(n)$ & $0$ \\
  CAIC & $log(n) + 1$ & $0$ \\
  SBIC & $log$\big($\frac{n+2}{24}$ \big) & $0$ \\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
\end{table}

For sample sizes greater than 8, we can see that BIC favours models with fewer estimated parameters and thus penalizes more heavily for each additional parameter in comparison to AIC. CAIC penalizes slightly more heavily than BIC due to the added estimated parameter terms in its penalty. Thus CAIC will smaller models more compared to BIC. ABIC is computed similarly as BIC, however, $log(n)$ is replaced with $log\big(\frac{n+2}{24}\big)$ which is based on the Rissanen Information Criteria (Rissanen, 1978) for autoregression models. Because of this term difference, BIC penalizes more harshly compared to ABIC for additional parameters included in the model. For samples larger than 176, ABIC will penalize the model more than AIC (Henson, Reise \& Kim, 2007). 

\subsection{Entropy based measures}
Finally entropy based measures are considered. Specifically we analyze the performance of relative entropy as described in Ramaswamy, DeSarbo, Reibstein, Robinson, 1993:

\begin{align}
    E = 1 - \frac{\sum_{i=1}^{n} \sum_{k=1}^{K} -p_{ik} \hspace{0.1em} log \hspace{0.1em} p_{ik}}{n \hspace{0.1em} log \hspace{0.1em} K}
\end{align} where $p_{ik}$ is individual $i$'s posterior probability of class membership. $E$ ranges from $0$ to $1$. 